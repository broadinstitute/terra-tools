{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Disclaimer:\n",
    "This Notebook is to be implemented at the user’s discretion. We are not responsible for any unexpected behavior (user error or otherwise). Please ensure that you have saved the files you would like to persist to the Data Model (or a more permanent location) before running this Notebook. </b>\n",
    "\n",
    "**What is this notebook?**\n",
    "\n",
    "This notebook offers you a way to delete workflow intermediates generated from a submission launched in a single Terra workspace. \n",
    "\n",
    "**What does it do?**\n",
    "1. (Optional) Lists the bucket size and storage cost for each workspace owned or created by the user\n",
    "2. Utilizes an optimized mop function to delete unwanted and/or unneccessary intermediate files.\n",
    "\n",
    "**What is the difference between this notebook and Remove_Workflow_Intermediates.ipynb?**\n",
    "\n",
    "The Remove_Workflow_Intermediates notebook uses the `mop` command from FISS, which times out for users that have very large workspaces to mop. This notebook calls an optimized `mop` function from the [broadinstitute/horsefish](https://github.com/broadinstitute/horsefish/blob/main/scripts/mop_workspace/mop_workspace.py) repo. This optimized function uses the Google Cloud Storage API and lists and deletes files in batches and processes them in parallel.\n",
    "\n",
    "This notebook also gives users the option to view the storage costs of their workspaces to determine which ones to mop.\n",
    "\n",
    "**What gets deleted?**\n",
    "\n",
    "Workflow output files minus logs are deleted except any outputs that are bound to the Data Model. To bind outputs to the Data Model, select Defaults from the Outputs section of the Workflow configuration before selecting \"Launch Analysis.\"\n",
    "\n",
    "**What gets left behind?**\n",
    "1. Files uploaded to the Google bucket that do not live inside a submission “directory” will NOT be deleted.\n",
    "2. Log files (stderr, stdout, *.log) within a submission “directory” will NOT be deleted.\n",
    "3. Submission folders/“directories” will NOT be deleted - only the contents.\n",
    "4. Notebooks in the Google bucket will NOT be deleted.\n",
    "\n",
    "**What should you do before using this notebook?**\n",
    "1. If there are outputs that should not be deleted, they will need to be bound to the Data Model. If a file is NOT bound to the Data Model, it will be removed.\n",
    "2. If not bound to the Data Model, desired files should be copied to a secondary location.\n",
    "\n",
    "**What should you do to run this notebook?**\n",
    "1. Clone this workspace or copy this notebook into the workspace you want to mop.\n",
    "2. Open the notebook and create a cloud environment. We recommend using the Default application configuration with 4 CPUs and 15 GB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone the git repo that contains the mop function\n",
    "branch = \"main\"\n",
    "! git clone -b $branch https://github.com/broadinstitute/horsefish.git\n",
    "! mv horsefish/scripts/mop_workspace/mop_workspace.py . \n",
    "! rm -Rf horsefish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install firecloud --upgrade\n",
    "!pip install hurry.filesize\n",
    "!pip install toolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import firecloud.api as fapi\n",
    "import os\n",
    "import pandas as pd\n",
    "from hurry.filesize import size\n",
    "from mop_workspace import mop, mop_files_from_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get the workspace storage cost\n",
    "def get_workspace_cost(workspace):\n",
    "    result = fapi.get_storage_cost(workspace[0],workspace[1])\n",
    "    if not result.ok:\n",
    "        return 'N/A'\n",
    "    return result.json()['estimate']\n",
    "\n",
    "# define a function to get the size of a workspace bucket\n",
    "def get_bucket_size(workspace):\n",
    "    result = fapi.get_bucket_usage(workspace[0],workspace[1])\n",
    "    if not result.ok:\n",
    "        return 'N/A'\n",
    "    return size(result.json()['usageInBytes'])\n",
    "\n",
    "# define a function to get the bucket name of a workspace\n",
    "def get_bucket_name(workspace):\n",
    "    result = fapi.get_workspace(workspace[0],workspace[1],'workspace.bucketName').json()['workspace']['bucketName']\n",
    "    return 'gs://'+result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# (Optional) Get workspace list\n",
    "\n",
    "In this section we are listing your workspaces and providing the workspace bucket size and storage cost for each workspace so you can make a decision on which workspace(s) to mop. You have the option to list only workspaces you created, or those that you have OWNER/PROJECT OWNER access to (this includes ones you created and those that have been created by others and shared with you).\n",
    "\n",
    "**If you already have a workspace you want to mop, skip to the next section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set environment variables\n",
    "current_user = os.getenv('OWNER_EMAIL') # get email of user currently running the notebook\n",
    "\n",
    "# User input required: \n",
    "# By default, we are only looking for workspaces that were created by the current user.\n",
    "# Change the following value to False if you want to get a list of all workspaces you have 'OWNER' and 'PROJECT OWNER' access to\n",
    "just_created_by = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get all workspaces that user has access to\n",
    "all_ws = fapi.list_workspaces(\"workspace.namespace,workspace.name,workspace.bucketName,workspace.googleProject,accessLevel,workspace.createdBy\").json()\n",
    "\n",
    "# uncomment next line to view the list\n",
    "#all_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Based on value in 'just_created_by', get list of workspaces\n",
    "if just_created_by:\n",
    "    my_workspaces = [(workspace['workspace']['namespace'], workspace['workspace']['name']) for workspace in all_ws if workspace['workspace']['createdBy'] == current_user]\n",
    "else:\n",
    "    my_workspaces = [(workspace['workspace']['namespace'], workspace['workspace']['name']) for workspace in all_ws if workspace['accessLevel'] in ('OWNER','PROJECT_OWNER')]\n",
    "\n",
    "# Uncomment next line to view the list\n",
    "#my_workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find workspace storage usage and costs for each workspace in 'my_workspaces'\n",
    "# Note: this may take a few minutes to run if you have a lot of workspaces\n",
    "my_workspaces_costs = [(my_workspaces[workspace][0],my_workspaces[workspace][1],get_bucket_size(my_workspaces[workspace]),get_workspace_cost(my_workspaces[workspace])) for workspace in range(len(my_workspaces))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**View the list of workspaces and their bucket sizes and storage costs. The list is shown in descending order by storage cost.**\n",
    "\n",
    "Note that in some cases, the API may have failed to get the storage cost for a workspace. We are filtering these out of the table view. If you are curious about what workspace(s) failed, comment out the last line in the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# configure dataframe\n",
    "df = pd.DataFrame(my_workspaces_costs)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.columns = ['Billing Project','Workspace Name','Bucket Size','Estimated Storage Cost']\n",
    "df = df.sort_values(['Estimated Storage Cost'], ascending=[0])\n",
    "df = df[(df['Estimated Storage Cost']!='N/A')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# view dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mop a workspace\n",
    "\n",
    "In this section we use the mop_workspace.py script to delete all intermediate files in a workspace. You have the option to input the billing project and name of a workspace you want to mop, or mop the current workspace that you are running this notebook in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select a workspace to mop:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the workspace_project and workspace_name values based on the workspace you want to mop\n",
    "workspace_project = 'my-billing-project-name'\n",
    "workspace_name = 'my-workspace-name'\n",
    "\n",
    "# Uncomment the next two lines if you want to mop the workspace that this notebook is currenty being run in.\n",
    "#workspace_project = os.getenv('WORKSPACE_NAMESPACE')\n",
    "#workspace_name = os.getenv('WORKSPACE_NAME')\n",
    "\n",
    "if not fapi.get_workspace(workspace_project,workspace_name).ok:\n",
    "    print(f\"Workspace '{workspace_project}/{workspace_name}' does not exist.\")\n",
    "    print(\"Check that you've entered the correct billing project and workspace name of an existing workspace before proceeding.\")\n",
    "else:\n",
    "    print(\"Workspace to mop:\")\n",
    "    print(f\"workspace_project = {workspace_project}\")\n",
    "    print(f\"workspace_name = {workspace_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dry run\n",
    "You can try a dry run first, which will write all files to be mopped to a text file that you can copy to a workspace bucket and inspect before deleting them.\n",
    "\n",
    "If you want to just mop the workspace without inspecting the files beforehand, you can skip to section **3.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get list of files that will be mopped\n",
    "files_to_mop_path = mop(project=workspace_project, workspace=workspace_name, include=None, exclude=None, dry_run=True, save_dir=\"mop_files\", yes=True, weeks_old=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of files gets saved to the VM disk, but in order to open and inspect the entire list, it's best to copy it to a workspace bucket. You can either copy it to the bucket of the workspace this notebook is currently running in, or the workspace bucket you are trying to mop (if it's different). By default we are copying the file to the workspace being mopped (i.e. the workspace you set in the beginning of this section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = get_bucket_name([workspace_project,workspace_name]) \n",
    "# Uncomment the next line if you want to copy the file to the bucket of the workspace this notebook is currently running in\n",
    "#bucket_name = os.getenv('WORKSPACE_BUCKET') \n",
    "bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy list of files to mop\n",
    "\n",
    "if files_to_mop_path:\n",
    "    ! gsutil cp $files_to_mop_path $bucket_name \n",
    "    print(f\"List of files to mop in workspace {workspace_project}/{workspace_name} copied to bucket {bucket_name}\")\n",
    "else:\n",
    "    print(\"No files to mop!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be able to download the list of files to mop from the bucket and inspect it.\n",
    "\n",
    "If you're ready to delete the files, run the next two cells. If the deletion fails due to an internal error while the mop script is running, it will retry up to 3 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "print(f\"All intermediate files in workspace \\033[1m'{workspace_project}/{workspace_name}'\\033[0m will be deleted. Do not proceed if this is incorrect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the files\n",
    "mop_files_from_list(workspace_project, workspace_name, files_to_mop_path, dry_run=False, yes=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional check to confirm bucket size is now smaller.\n",
    "mopped_bucket = get_bucket_name([workspace_project,workspace_name])\n",
    "!gsutil du -sh $mopped_bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just mop\n",
    "\n",
    "If you don't want/need to inspect the files beforehand, run the following cell to just delete the files. If the deletion fails due to an internal error, it will retry up to 3 times.\n",
    "\n",
    "Note that the function will still write a list of files that were deleted, which you can download from the VM disk and inspect afterwards if desired. See section 3.1 for guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_mop_path = mop(project=workspace_project, workspace=workspace_name, include=None, exclude=None, dry_run=False, save_dir=\"mop_files\", yes=True, weeks_old=3, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
